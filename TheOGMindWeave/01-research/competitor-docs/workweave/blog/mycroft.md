# How Mycroft proved slowing down to speed up was the right decision for their engineering team - Remote

> Weave combines LLMs and domain-specific machine learning to understand engineering work. We understand how much work was done by AI vs. humans. How much AI is helping your team ship faster, if it's having an impact on code quality and code reviews.

- ## ## ## ## ## - ## $4.2M seed round led by Moonfire, Burst Capital & Y Combinator

$4.2M seed round led by Moonfire, Burst Capital & Y Combinator

*Written in collaboration with Mycroft and Weave*

There’s a moment every eng leader has—quiet, internal, heavy. It’s the moment after you’ve made the call: ship the refactor, trust the engineers, burn weeks (maybe months) rewriting systems no customer will ever see.

For Mycroft CTO Jan, that moment happened in late 2024. He and his team had just pulled the trigger on a major infrastructure overhaul. It was painful, necessary, and invisible.

And for a while, it felt like they were flying blind.

“We knew it was the right thing to do,” Jan said. “But we didn’t know how to prove it in the long run.”

**The Skepticism Phase**

When Jan and CEO Mike first heard about Weave—a tool that promised visibility into engineering performance without resorting to vanity metrics or micromanagement—they hesitated.

“We were skeptical,” Mike admitted. “We thought the team would hate it.”

Jan nodded. “We thought engineers would feel like they were being judged, not understood.”

But they were also staring down a wall of ambiguity. There were questions the leadership team couldn’t answer:

Was the refactor worth it?
- Were engineers focused on what mattered?
- Were tools like Cursor helping or hindering?

So they tried it.

“Within days,” Jan said, “we were seeing patterns we’d never seen before.”

**The Data Didn’t Lie**

The team had wrapped their refactor in December 2024. It had been disruptive—output slowed, the system quieted. But then something remarkable happened.

By January, productivity didn’t just rebound. It surged. Then February—still strong. March? Even better.

*Mycroft's engineering output, tracked in Weave. The refactor (Nov–Dec ‘24) paved the way for performance gains that exceeded top benchmarks in Q1 ‘25.*

“We could finally*see*the ROI,” Jan said. “It wasn’t anecdotal anymore. The data told the truth.”

And for one engineer in particular, that truth was personal.

“She saw that she’d led the most impactful work of the week. She literally fist-pumped when she saw the report.”

**From Reporting to Ritual**

What began as an experiment became part of the Mycroft culture. Weave’s weekly reports weren’t just skimmed—they became a ritual.

“People would check the numbers to see if they were trending in the right direction,” Jan said. “Not to compete, but to understand: Am I working on what matters most?”

Mike added, “That was the surprise for me. I thought this would feel like oversight. But the team kept saying: ‘This is amazing.’ That was their word—not ours.”

“I expected resistance,” Mike told me. “But instead, I had engineers coming up to me saying, ‘This is amazing.’ I didn’t see that coming.”

Now, the Mycroft team looks forward to their Weave reports. “There’s a bit of healthy competition,” Jan laughed. “People are curious—*'How did I do this week?'*It’s not about being the best. It’s about getting better.”

They use the weekly reports to understand performance and make sure that the team is focused on the right activities to push the business forward—the most impactful work.

Mike also leaned into gamification to amplify that momentum.

“We started celebrating top engineers of the week. We’d call it out in meetings. It got people genuinely excited—like, we had fist pumps over Weave scores,” Mike said. “But it wasn’t just about recognition. We could also spot when someone was going*too*hard, and that let us step in before burnout hit. That’s the kind of insight we didn’t have before.”

And Weave’s impact goes beyond just team performance.

**Cursor, Proven in Context**

Like many engineering teams, Mycroft was experimenting with AI tools to boost productivity. Cursor, their code co-pilot, was promising—but was it actually moving the needle?

“We used Weave to isolate the effect Cursor was having on our team,” Jan explained. “We could track before-and-after data. The impact was clear.”

Weave became their litmus test for every investment. It replaced gut instinct with context, anecdotes with evidence.

**What Clarity Feels Like**

Ask Jan what the biggest benefit has been, and he’ll tell you it wasn’t just the velocity gains. It was the*confidence*.

“As a CTO, you constantly wonder: Are we building the right thing? Are we moving fast enough? Are we getting in our own way? Weave doesn’t just help you answer those questions. It helps you sleep.”

**The Bottom Line**

For Mycroft, Weave delivered:

Objective validation of a complex refactor
- Increased engineering velocity—sustained above top 10% benchmarks
- Elevated morale through visibility and recognition
- Clear measurement of tooling investments like Cursor
- A cultural shift toward aligned, impactful work

“It’s not about tracking,” Jan said. “It’s about understanding. Everyone knows what good looks like now—and we’re all aiming for it together."

Article written by

Adam Cohen

Make AI Engineering Simple

Effortless charts, clear scope, easy code review, and team analysis

Book a demo

Book a demo

Book a demo

Book a demo

Book a demo

Book a demo